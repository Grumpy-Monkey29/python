{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Grumpy-Monkey29/python/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import shap\n",
        "\n",
        "# Data\n",
        "X = pd.DataFrame({\n",
        "    \"F1\": [5.0, 5.1, 5.2, 5.0, 5.1, 4.9, 5.3, 5.0, 9.5, 2.0],\n",
        "    \"F2\": [3.0, 3.1, 3.2, 3.0, 3.1, 3.1, 3.3, 3.0, 7.5, 1.0],\n",
        "    \"F3\": [1.5, 1.4, 1.3, 1.5, 1.4, 1.5, 1.6, 1.5, 6.0, 0.5],\n",
        "    \"F4\": [0.2, 0.2, 0.2, 0.2, 0.2, 0.1, 0.3, 0.2, 2.0, 0.1]\n",
        "})\n",
        "\n",
        "model = IsolationForest(random_state=42)\n",
        "model.fit(X)\n",
        "\n",
        "scores = -model.decision_function(X)  # higher = more anomalous\n",
        "X[\"is_anomaly\"] = model.predict(X) == -1\n",
        "X[\"anomaly_score\"] = scores\n",
        "\n",
        "\n",
        "print(X)\n"
      ],
      "metadata": {
        "id": "zTabTX1jswnK",
        "outputId": "934c7633-1e3a-4049-9e98-79a39cc84f1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    F1   F2   F3   F4  is_anomaly  anomaly_score\n",
            "0  5.0  3.0  1.5  0.2       False      -0.163741\n",
            "1  5.1  3.1  1.4  0.2       False      -0.158161\n",
            "2  5.2  3.2  1.3  0.2       False      -0.067609\n",
            "3  5.0  3.0  1.5  0.2       False      -0.163741\n",
            "4  5.1  3.1  1.4  0.2       False      -0.158161\n",
            "5  4.9  3.1  1.5  0.1       False      -0.075971\n",
            "6  5.3  3.3  1.6  0.3        True       0.007874\n",
            "7  5.0  3.0  1.5  0.2       False      -0.163741\n",
            "8  9.5  7.5  6.0  2.0        True       0.280548\n",
            "9  2.0  1.0  0.5  0.1        True       0.179479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(model, X.drop(columns=[\"anomaly_score\", \"is_anomaly\"]))\n",
        "shap_values = explainer(X.drop(columns=[\"anomaly_score\", \"is_anomaly\"]))\n",
        "\n",
        "shap_df = pd.DataFrame(shap_values.values, columns=X.columns[:-2])\n",
        "combined = pd.concat([X, shap_df.add_prefix(\"shap_\")], axis=1)\n",
        "print(combined.round(3))\n",
        "\n",
        "# shap.plots.waterfall(shap_values[1])  # For row 9 (anomalous high values)\n",
        "# shap.plots.waterfall(shap_values[2])  # For row 9 (anomalous high values)\n",
        "# shap.plots.waterfall(shap_values[6])  # For row 9 (anomalous high values)\n",
        "# shap.plots.waterfall(shap_values[8])  # For row 9 (anomalous high values)\n",
        "# shap.plots.waterfall(shap_values[9])  # For row 10 (anomalous low values)\n"
      ],
      "metadata": {
        "id": "ndwsyLd6u1bJ",
        "outputId": "46774558-f5a6-45a3-e1de-6bf50bb3e488",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    F1   F2   F3   F4  is_anomaly  anomaly_score  shap_F1  shap_F2  shap_F3  \\\n",
            "0  5.0  3.0  1.5  0.2       False         -0.164    0.319    0.256    0.368   \n",
            "1  5.1  3.1  1.4  0.2       False         -0.158    0.293    0.314    0.252   \n",
            "2  5.2  3.2  1.3  0.2       False         -0.068   -0.014    0.068   -0.386   \n",
            "3  5.0  3.0  1.5  0.2       False         -0.164    0.319    0.256    0.368   \n",
            "4  5.1  3.1  1.4  0.2       False         -0.158    0.293    0.314    0.252   \n",
            "5  4.9  3.1  1.5  0.1       False         -0.076    0.041    0.245    0.299   \n",
            "6  5.3  3.3  1.6  0.3        True          0.008   -0.225   -0.283    0.062   \n",
            "7  5.0  3.0  1.5  0.2       False         -0.164    0.319    0.256    0.368   \n",
            "8  9.5  7.5  6.0  2.0        True          0.281   -0.599   -0.774   -0.795   \n",
            "9  2.0  1.0  0.5  0.1        True          0.179   -0.743   -0.653   -0.789   \n",
            "\n",
            "   shap_F4  \n",
            "0    0.395  \n",
            "1    0.390  \n",
            "2    0.310  \n",
            "3    0.395  \n",
            "4    0.390  \n",
            "5   -0.502  \n",
            "6   -0.445  \n",
            "7    0.395  \n",
            "8   -1.048  \n",
            "9   -0.281  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# explainer = shap.Explainer(model, X.drop(columns=[\"anomaly_score\", \"is_anomaly\"]))\n",
        "# shap_values = explainer(X.drop(columns=[\"anomaly_score\", \"is_anomaly\"]))\n",
        "\n",
        "shap.plots.beeswarm(shap_values)\n"
      ],
      "metadata": {
        "id": "TJIhXrZGwaeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation"
      ],
      "metadata": {
        "id": "ZsaCBJsTsqAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The user wants to understand how to interpret the is_anomaly column (which indicates if a data point is an anomaly) based on the shap_values and the anomaly_score calculated by the Isolation Forest model.\n",
        "\n",
        "The anomaly_score is a direct output of the Isolation Forest model, indicating the degree of anomalousness (higher score means more anomalous). The is_anomaly column is a binary classification based on a threshold applied to this score. The shap_values, on the other hand, explain why a specific data point received its anomaly_score. `Each SHAP value for a feature represents the contribution of that feature's value to the difference between the predicted score for that instance and the base value (average prediction)`.\n",
        "\n",
        "Therefore, to interpret is_anomaly using SHAP values and anomaly_score, we need to:\n",
        "\n",
        "Understand that anomaly_score is the primary driver for is_anomaly.\n",
        "Use SHAP values to understand which features contributed positively or negatively to the anomaly_score of a particular instance.\n",
        "Higher positive SHAP values for a feature mean that the feature's value for that instance pushed the prediction towards a higher anomaly_score (more anomalous).\n",
        "Lower or negative SHAP values for a feature mean that the feature's value for that instance pushed the prediction towards a lower anomaly_score (less anomalous).\n",
        "Suggested Changes\n",
        "\n",
        "Here's how you can interpret the is_anomaly using the available information:\n",
        "\n",
        "anomaly_score: This is the most direct measure. Instances with a high anomaly_score are flagged as is_anomaly = True. The specific threshold for determining is_anomaly is implicitly set by the Isolation Forest model's internal logic (typically based on quantiles or the contamination parameter if specified, although it wasn't in this case, so the default threshold is used).\n",
        "\n",
        "SHAP Values (shap_values): For any given data point (row in your DataFrame), the SHAP values for each feature (F1, F2, F3, F4) explain how much that feature's value contributed to the anomaly_score of that point, relative to the average anomaly_score across the dataset.\n",
        "\n",
        "If a data point is marked as an anomaly (is_anomaly = True) and has a high anomaly_score, look at its SHAP values. Features with large positive SHAP values are the main contributors to that point being flagged as an anomaly. For example, if a data point has a very high value for F1 and a large positive SHAP value for F1, it means that the high value of F1 significantly increased the anomaly_score, leading to it being classified as an anomaly.\n",
        "If a data point is not marked as an anomaly (is_anomaly = False) and has a low anomaly_score, its SHAP values will typically be smaller in magnitude, and potentially negative for some features if their values are \"normal\" and thus reduce the anomaly score.\n",
        "Combining for Interpretation:\n",
        "\n",
        "For an instance where is_anomaly is True: The anomaly_score is high. Use the SHAP values for this instance to identify which features (the ones with large positive SHAP values) are primarily responsible for this high score and thus for the instance being flagged as an anomaly. Examine the actual values of these influential features (F1, F2, etc.) in the original X DataFrame to understand what makes them anomalous.\n",
        "For an instance where is_anomaly is False: The anomaly_score is low. The SHAP values for this instance will typically be close to zero or negative for features, indicating that the feature values for this instance are \"normal\" and do not significantly contribute to a high anomaly score.\n",
        "In essence, the anomaly_score tells you how anomalous a point is, is_anomaly tells you if it's classified as an anomaly based on a threshold, and SHAP values tell you why it received that anomaly_score by attributing the contribution to each feature.\n",
        "\n",
        "You can use the combined DataFrame you created to visually inspect the anomaly score, the anomaly classification, and the SHAP values side-by-side for each data point. For instance, you can sort the combined DataFrame by anomaly_score or filter for is_anomaly == True and then look at the corresponding shap_F1, shap_F2, etc. columns to understand the feature contributions."
      ],
      "metadata": {
        "id": "seZyFT874AWx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
